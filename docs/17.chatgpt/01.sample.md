# ChatGPTとの連携

## サンプルの作成

DLIのDockerはPython3.6なので、一般的なOpenAIのAPIは使用できないので、RESTのやり取りを全部自作する。

Completion APIとのやり取りをするプログラムを作成し、ChatGPTとの連携をおこなう。
https://platform.openai.com/docs/guides/gpt/completions-api


必要なもの
- OpenAIのAPIキー


```
# -*- coding: utf-8 -*-
import readline
import requests
import json

# OpenAI APIキーを設定します（ご自身のキーに置き換えてください）
api_key = "#################################################"

# 使用するモデルの設定を行います
model_engine = "gpt-3.5-turbo"

# GPT-3から応答を生成する関数
def generate_response(prompt, system_roll, model_engine):
    # OpenAIのURL
    url = "https://api.openai.com/v1/chat/completions"
    headers = {'Authorization': 'Bearer {}'.format(api_key)}
    data = {
        "model": model_engine,
        "messages":[
            {"role": "system", "content": system_roll},
            {"role": "user", "content": prompt}
        ],
    }
    response = requests.post(url, headers=headers, json=data)
    try:
        # 応答からメッセージを取り出す
        message = response.json()["choices"][0]["message"]["content"]
        return message
    except Exception as e:
        print("Error: " + str(response) + " Exception: " + str(e))
        return None

# メインループ
def main():

    while True:
        prompt = ""
        # ユーザーからの入力を受け取る
        user_input = input("> ")

        # ユーザーの入力をGPT-3 APIに送信して応答を生成する
        prompt += user_input + "\n"
        response = generate_response(prompt,"",model_engine)

        # ChatGPTの応答を表示する
        print(response)

# プログラムのエントリーポイント
if __name__ == "__main__":
    main()
```